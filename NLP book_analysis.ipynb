{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9acb9d0b-5bbb-4906-b93c-c4fcd0e4a80b",
   "metadata": {},
   "source": [
    "# Work with Nature Language Programming Book Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f96844-098b-4405-b145-e54b3af3e50f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c440bd8-f9d8-476f-a02e-44e0ce7fd4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "filepath: str = glob('*.txt')[0]\n",
    "with open(filepath, encoding='utf-8') as output:\n",
    "    book: str = output.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1016d73f-3056-4322-a356-2b24b3df4bf9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## The most used words(non-articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f40262ac-cc47-4904-9c56-a2b6cd5e1b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro temos de descobrir as palavras mais usadas com articles, como fizemos no outro ficheiro:\n",
    "import re\n",
    "pattern = re.compile('[a-zA-Z]+')\n",
    "findings: list = re.findall(pattern, book.lower())\n",
    "d: dict = {}\n",
    "for word in findings:\n",
    "    if word in d:\n",
    "        d[word] += 1\n",
    "    else:\n",
    "        d[word] = 1\n",
    "d_list: list = sorted([(value, key) for key, value in d.items()], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1615af53-9cfd-48c6-8f84-d95dcc9d506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from platform import python_version\n",
    "# python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc988553-3fe2-4bb7-b781-daa062bf90c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\cmmon\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\cmmon\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\cmmon\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\cmmon\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cmmon\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\cmmon\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# !pip3.12 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0929037-9895-420c-9fd9-4b2115f74ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cmmon\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Vamos importar nlp library, para trabalhar com natural language programming\n",
    "# Sobre o módulo nltk:\n",
    "# O Natural Language Toolkit (nltk) é uma biblioteca de código aberto e popular para natural language Processing (PLN) em Python. Ele fornece uma ampla gama de ferramentas para analisar,\n",
    "# entender e gerar linguagem humana.\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69543ba1-3fde-4929-a644-f6994938ec72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(575, 'would'), (519, 'us'), (292, 'said'), (284, 'roberto'), (252, 'could')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words: list = []\n",
    "for count, word in d_list:\n",
    "    if word not in english_stopwords:\n",
    "        filtered_words.append((count, word))\n",
    "filtered_words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b3d44b-70ab-4730-84ea-3879940106fe",
   "metadata": {},
   "source": [
    "## Sentimental Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81793f48-2464-4f50-855e-363ad63906b6",
   "metadata": {},
   "source": [
    "### An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d90e543f-c484-4ecb-b702-f15a323fddb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\cmmon\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56c15423-f19c-4fee-aadf-3e242f92b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "# dir(analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0f59c0c-8d2d-4026-b626-cc6a2963c02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.606, 'pos': 0.394, 'compound': 0.5994}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores('Hey, look how beautiful the trees are.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a0bd3b4-8803-4262-8780-fe0f83539a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.464, 'pos': 0.536, 'compound': 0.8442}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores('Hey, look how beautiful the trees are.I love them')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5a05612f-dca3-478b-9e50-5830faa85265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.378, 'pos': 0.622, 'compound': 0.959}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores('Hey, look how beautiful the trees are.I love them. I really love them. Its look like heaven')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5d7e6c4-0c91-4be1-bd4e-b25fe70eafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrore = analyzer.polarity_scores('Hey, look how bad the trees are.I hate them. I really hate them. Its look like hell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "44fbbfc8-787f-40e8-ad7a-bafb7360b75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a positive text\n"
     ]
    }
   ],
   "source": [
    "if scores['pos'] > scores['neg']:\n",
    "    print('It is a positive text')\n",
    "else:\n",
    "    print('It is a negative text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e315fd7b-436a-49fe-9f62-018c367d64bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.116, 'neu': 0.76, 'pos': 0.125, 'compound': 1.0}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a12dbe9-0b7e-40dd-9d40-0a334a98bf8b",
   "metadata": {},
   "source": [
    "### What is the most positive chapter and the most negative chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d6bf6e4-76dc-48cf-b911-6641525869fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'neg': 0.061, 'neu': 0.779, 'pos': 0.16, 'compound': 1.0}\n",
      "2 {'neg': 0.12, 'neu': 0.726, 'pos': 0.154, 'compound': 0.9991}\n",
      "3 {'neg': 0.145, 'neu': 0.751, 'pos': 0.105, 'compound': -0.9999}\n",
      "4 {'neg': 0.141, 'neu': 0.721, 'pos': 0.138, 'compound': -0.9963}\n",
      "5 {'neg': 0.118, 'neu': 0.742, 'pos': 0.141, 'compound': 0.9997}\n",
      "6 {'neg': 0.124, 'neu': 0.761, 'pos': 0.115, 'compound': -0.9979}\n",
      "7 {'neg': 0.136, 'neu': 0.761, 'pos': 0.103, 'compound': -0.9999}\n",
      "8 {'neg': 0.12, 'neu': 0.786, 'pos': 0.094, 'compound': -0.9998}\n",
      "9 {'neg': 0.097, 'neu': 0.824, 'pos': 0.079, 'compound': -0.9996}\n",
      "10 {'neg': 0.086, 'neu': 0.733, 'pos': 0.181, 'compound': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile('Chapter [0-9]+')\n",
    "chapters = re.split(pattern, book)[1:]\n",
    "# vai criar uma lista, onde cada elemento é um capítulo\n",
    "analyzer.polarity_scores(book)\n",
    "positive = {}\n",
    "for number, chapter in enumerate(chapters):\n",
    "    scores = analyzer.polarity_scores(chapter)\n",
    "    print(number + 1, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a9fc9-4680-4cd0-b2a1-54c71caeead3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
